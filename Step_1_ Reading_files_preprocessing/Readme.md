# Step 1:-

Write a python script to perform the following data preparation activities:
1. Tokenize the corpus
2. Remove the following special characters: !"#$%&()*+/:;<=>@[\\]^`{|}~\t\n
3. Create two versions of your dataset: (1) with stopwords and (2) without stopwords.
Stopword lists are available online.
4. Randomly split your data into training (80%), validation (10%) and test (10%) sets.



